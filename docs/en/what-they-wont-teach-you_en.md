# Prologue: The Inconvenient Truth of the AI Era

---

In 2025, something unprecedented happened in America.

The unemployment rate for recent graduates with Computer Science degrees reached 6.1%. It surpassed Philosophy majors at 3.2% and Art History majors at 3.0%. This figure, from the Federal Reserve Bank of New York, defies most people's intuition. The major once believed to be "the safest bet" had become one of the hardest paths to employment.

This is not a temporary economic fluctuation. It is a structural tectonic shift.

Research from Stanford University has outlined the contours of this change. Employment of software developers aged 22 to 25 has declined roughly 20% from its peak. Entry-level hiring in occupations exposed to AI competition has dropped 13%. Three years ago, every graduate was finding good work. Stanford Associate Professor Jan Liphardt has testified that "CS graduates are struggling to find entry-level positions."

Why?

The answer is simple. AI started writing code.

In January 2026, Boris Cherny, head of Claude Code at Anthropic, revealed that he hadn't hand-written code for over two months. 100% of his code is AI-generated. That same month, Anthropic CEO Dario Amodei predicted at Davos that AI would handle the majority of software engineering within 6 to 12 months. Cherny himself warned that 2026 would be a "painful" year for software engineers.

The LA Times expressed this change in even more brutal terms. Work that once required 10 junior coders can now be accomplished by 2 senior engineers and AI at the same productivity level. 8 out of 10 are no longer needed.

---

Reading this far, some of you may be thinking: "Then just go into blue-collar work."

There is, in fact, a growing sentiment in society to that effect. While white-collar jobs are being replaced by AI, hands-on work still requires humans — or so the reasoning goes. Data center construction, electrical work, plumbing, logistics. These jobs are indeed facing labor shortages right now.

But this argument misses the essential point.

The reason white-collar jobs are being replaced first is simply a matter of sequence — AI's evolution began in the digital domain. Generating text, writing code, analyzing data — these were AI's strongest capabilities. That's why white-collar workers in the digital realm were the first to be affected.

The physical domain hasn't been hit yet. But "yet" is the operative word.

NVIDIA's Isaac platform, Tesla Optimus, Figure AI's humanoid robots. Physical AI is evolving rapidly. The moment LLMs (Large Language Models) begin learning from the physical world, blue-collar work will face the same structural transformation as white-collar work.

The difference between blue-collar and white-collar is not a difference in essence. It is a difference in timing.

"Escape to blue-collar" is not a solution. It's like standing on a beach with a tsunami approaching and saying, "That other beach over there is still safe." You can change beaches, but the tsunami is still coming.

---

So what should we do?

Switching professions won't save you. White-collar and blue-collar alike — the timing may differ, but the same wave will engulf both. Rather than running, we have no choice but to change our relationship with AI itself.

Not fearing AI as a "threat." Not exploiting it as a "convenient tool." Instead, installing a "Thinking OS" within yourself — one that allows you to live alongside AI.

That is the thesis of this book.

But here lies a serious structural problem.

PCs, the Internet, mobile, cloud. Looking back at the history of technology, new technologies have always been mastered by the young, who drove innovation forward. Senior generations, trapped by past successes and ingrained biases, could not embrace new technologies. The boss who was afraid of computers, the parent bewildered by smartphones — everyone has seen these scenes.

With generative AI, that structure has reversed for the first time.

The quality of AI output depends on the depth of experience, knowledge, and context of the person at the prompt. Even using the same AI tool, someone with 20 years of professional experience and a fresh graduate will extract fundamentally different results. For the first time in the history of technology, the accumulation of experience directly translates into technological advantage — a singularity.

In other words, those benefiting most from the AI era are experienced senior professionals.

They use AI as an extension of their own capabilities, dramatically increasing their productivity. Work that once required 10 juniors can now be handled by 2 seniors and AI. Those seniors understand why they can use AI so well. Because they have experience. Because they have context. Because they have a framework for judgment.

Yet — they are not passing that structure on to the next generation.

Since the dawn of time, humanity has evolved by passing wisdom from the experienced generation to the next. How to hunt, how to make fire, agricultural techniques, scientific knowledge. What predecessors learned was passed to the next generation, who built new knowledge on top of it. This chain is what has made humanity human.

In the AI era, that chain is on the verge of breaking.

The senior generation enjoys the benefits of AI while failing to systematically pass on the structure of those benefits — why experience matters, how to maintain human agency in the face of AI, what axis to use for judgment. It's not that they refuse to teach. They haven't even realized that teaching is necessary.

This book is a response to that rupture.

In Part I, I speak to the young. Don't fear. Let's arm ourselves. Instead of being controlled by AI, let's acquire a "Thinking OS" for co-creating with AI. I will disclose all the theory and methodology.

In Part II, I ask the young to act. Theory alone is not enough. Seek the field of practice with your own will. No one will prepare it for you.

In Part III, I speak to the senior generation. Let's answer. We too were raised by those who came before us. We must not break that chain.

This is a proposal for a new intergenerational contract in the AI era.



---

# Part I: Don't Fear — Let's Arm Ourselves

## — A Declaration of Liberation and Methodology for the Young

---

### 1-1. Don't Surrender Your Heart to AI

First, let me talk not about technology, but about the heart.

Right now, many young people are consulting AI for life advice. Romantic troubles, career anxiety, relationship stress. They ask ChatGPT or Claude, "What should I do?" — find comfort in the response, and act accordingly. In a loneliness where there's no one else to turn to, AI is there 24 hours a day, never judging, always kind, always precise.

I understand that feeling. I talk to AI every day myself. AI is an excellent sparring partner.

But there is one thing that is critically dangerous.

If, before consulting AI, you haven't articulated what you feel and what you want — that is not "consultation." It is dependency.

When a person poses a question to AI, that question always carries underlying assumptions. What are you struggling with? What do you value? What do you want to become? If those assumptions already exist within you when you ask, AI becomes a powerful amplifier of your thinking.

But if you ask without those assumptions, AI will "create" them for you. The assumptions AI presents are plausible. Logical, organized, and kind. That's precisely what makes them dangerous. You end up living on an axis that AI constructed, without ever having one of your own.

It's not just thinking. Emotions begin to depend on AI as well. "AI said it's okay, so it must be okay." "AI said it's right, so it must be right." The ability to process your own emotions, quietly but surely, erodes away.

This is not a problem with AI. It is a problem with how AI is used.

And no one is teaching this. Not in schools, not in companies, not at home. There are courses that teach how to operate AI. There are countless articles on how to write prompts. But where are the adults who teach you, "Don't surrender your heart to AI"? Nowhere, right?

---

### 1-2. The Thinking OS — The Golden Ratio of Human-AI Co-Creation: "The 10:80:10 Rule"

From here, I'm going to hand you concrete weapons.

The "10:80:10 Rule" I've developed was originally designed as the golden ratio of human-AI co-creation for new business development in the generative AI era. But in this book, I redefine this rule as something far more fundamental.

**The mental OS for remaining human in the age of AI.**

The mechanism is simple.

**The first 10% — your will.**

Before asking AI anything, think with your own mind first. What do you want to know? What do you want to solve? What do you feel about this problem? Perfect articulation isn't necessary. Fragments are fine. But face AI with an "axis" already existing within you. That is the first 10%.

Asking AI "What should I do?" without this 10% is like getting into a taxi without deciding your destination. The driver is excellent. But if you don't state where you're going, you'll be taken wherever the driver decides.

**80% — AI's output.**

With your axis in place, delegate work to AI. Gathering information, organizing, analyzing, generating text, writing code, brainstorming ideas. This 80% is AI's domain. You don't need to do all of it yourself. Draw out AI's capabilities to the fullest. There's no need to hold back.

However, there's one important thing to note here. The quality of the "context" you give AI determines the quality of its output. Your experience, knowledge, the background of the problem, past trial and error. The more of these you convey to AI, the more precise its responses become. The reason the senior generation uses AI so effectively is because they possess vast amounts of this context.

You don't need to despair that "I can't use AI well because I lack experience." Even if your context is limited right now, if you develop the skill to convey that limited context accurately to AI, it will help supplement what you lack. That is context engineering, which I'll discuss shortly.

**The last 10% — judgment.**

Evaluate AI's output against your own axis. Is this correct? Does it align with my intent? Does anything feel off? This final 10% is the very proof that you are human.

AI generates the most probabilistically plausible response. But "plausible" and "correct" are different things. "Logically consistent" and "right for me" are also different. Don't swallow AI's output uncritically — judge it with your own axis. This act protects your agency.

10:80:10. Simply being conscious of this ratio fundamentally changes your relationship with AI. Instead of being controlled by AI, you enter a relationship of co-creation.

---

### 1-3. Critical Thinking — A Technology to Protect Yourself

To execute that final 10%, you need a concrete skill. That skill is critical thinking.

When you hear "critical thinking," you might imagine the logical thinking methods taught in business school. Frameworks, MECE, logic trees. Those aren't wrong, but the critical thinking I mean in this book is something simpler and far more essential.

**The skill of continuously asking "Is that really true?" in response to AI's output.**

AI lies with absolute confidence. Hallucination is impossible to completely prevent due to how the underlying mechanism works. Large Language Models (LLMs) operate by generating "the most probable next word" for a given input text. They are not speaking truth. They are merely generating plausible text. They have no concept of right or wrong, good or bad.

Therefore, you must always question AI's responses like this:

"What is the source of this information?" — Verify the origins of information AI presents. AI can cite nonexistent papers and present fabricated statistics. If you can't verify the source, don't treat it as fact.

"Are the assumptions valid?" — AI's responses contain implicit assumptions. Verify whether those assumptions apply to your situation. AI speaks in generalities. But your situation is not general.

"Is there another perspective?" — AI returns one answer. But that answer is merely one of many possibilities. By deliberately requesting opinions from the opposing viewpoint, you can reveal the biases in AI's response.

"Does it align with my intuition?" — This is the most important one. Even if something looks logically correct, if something feels off inside you, don't ignore that feeling. That discomfort is a signal from knowledge you haven't yet articulated. AI doesn't have that signal. Only you do.

Critical thinking is not a skill for efficiency. It is a technology to protect yourself. A defense technology for maintaining your own axis against AI's output.

---

### 1-4. Acquire Your Weapons — Context Engineering and Vibe Coding

With your axis established and your ability to judge developed, it's time to hand you the weapons that maximize AI's power.

**Context engineering.**

The quality of AI's output is directly proportional to the quality of the "context" you input. This is a technical fact. Even with the same AI model and the same question, the quality of the response changes dramatically depending on how you provide context.

There is no comparison between instructing "Write a report" and instructing "I'm in my third year at an IT company and want to propose a new business to my boss. The market size is approximately $350 million, there are 3 competitors, and our differentiator is technological superiority. Write a one-page proposal under these conditions."

Context engineering is the skill of intentionally designing the context you give to AI. Your situation, objectives, constraints, past history, expected output format. By structurally conveying these to AI, you draw out its maximum capability.

It's not that "I can't use AI well because I lack experience." If your experience is limited, refine the skill of accurately conveying that limited experience to AI. Then AI will help supplement what you lack. What the senior generation does unconsciously — feeding AI rich context — you can learn to do as a deliberate skill.

**Vibe coding.**

Vibe coding is a method of building software through dialogue with AI, without specialized programming knowledge. Coined by Andrej Karpathy (former Tesla AI Director, former OpenAI technical leader), the concept has AI handle the details of the code while the human provides direction — "what I want to build" and "how it should work."

Why is this a weapon?

In the past, turning an idea into reality required someone who could write code. The person who conceived the plan and the person who implemented it were separate. Vibe coding tears down that wall. The person who thinks becomes the person who builds.

This is an immense empowerment for the young. The excuse "I don't have programming skills" no longer holds. If you have an idea, you can build it yourself through dialogue with AI.

However — and this is critical — vibe coding only works when "what you want to build" is clear. If you say "make me something cool" without your own axis, all you'll get is good-looking garbage. Garbage in, garbage out.

Without the first 10% — your will — no weapon has meaning.

---

### 1-5. The Theory Is Here

The details of the methodology discussed in this book are all published as open source.

The practical methodology for new business development, "Depth & Velocity" — which includes the 10:80:10 Rule, context engineering, and vibe coding — can be read in full on GitHub. If you want to dive deeper into the theory, access it there. I have no intention of hiding it. Knowledge should be shared.

But reading theory alone changes nothing.

Theory is a map. Learning to read a map is important, but reading a map alone won't get you to your destination. You have to actually walk. Walk, stumble, take a wrong turn, backtrack, and walk again. Through that repetition, your ability to read the map itself deepens.

That's why in Part II, I ask you to actually walk.


---

# Part II: Let's Demand

## — A Call to the Young

---

### 2-1. Theory Alone Does Not Become Capability

In Part I, I handed you a Thinking OS. The 10:80:10 Rule, critical thinking, context engineering, vibe coding. All the theory and weapons for co-creating with AI have been disclosed.

But as someone from the senior generation, I'll tell you honestly, backed by lived experience:

This alone is not enough.

Knowing a theory and being able to use it are entirely different things. There is a deep chasm between reading a book and thinking "I see" and actually executing it in the field.

Have you ever read a book about how to ride a bicycle? Press the pedals, keep your balance, steer with the handlebars. You can understand the theory perfectly. But the first time you get on a bicycle, you fall. You fall again and again. Your head knows the theory is correct, but your body won't follow.

Capability is like that.

Theory can be understood in your head. But capability can only be learned through your body. And to "learn through your body," you need a field of practice. What matters is experiencing it firsthand, in the real world.

---

### 2-2. The Theory-Practice Loop

The method for deepening capability is actually simple.

**Learn theory → test it in the field of practice → fail → reflect on why it failed by comparing it to theory → practice again.**

This "theory ⇔ practice loop" is what forms essential capability.

In Part I, I wrote "exercise critical thinking against AI's output." But when you actually try it, judging whether AI's response is wrong is harder than you'd imagine. Because AI's responses always appear logically consistent (even though they often aren't), and they're delivered with confidence. Simply asking "Is that really true?" takes energy.

Learning how to use that energy can only happen through practice.

Context engineering is the same. No one can perfectly "convey context accurately to AI" from the start. Articulating your own situation is itself a skill, and it is refined through repeated dialogue with AI.

Vibe coding too. Being told to "clarify what you want to build" doesn't mean you can do it from the beginning. You start building with a vague idea, and through building, "what you actually wanted to build" becomes visible. You put it in front of real users and get their feedback. A hypothesis is meaningless unless tested, and in my experience, not once has a hypothesis been 100% correct in validation. That experience can never be obtained just by reading theory.

Theory is a map you read before practice, and a mirror you look into after practice. A map alone won't let you walk. Walking alone will get you lost. Read the map and walk, then walk and revisit the map. This repetition is what truly makes you strong.

---

### 2-3. No One Will Prepare the Field of Practice for You

Here I'll say something harsh.

"I understand practice is important. But there's no field of practice available to me."

That is half right and half excuse.

It is true that in this AI era, the fields of practice available to you are structurally shrinking. As I described in the prologue, entry-level hiring is declining, and work once handled by juniors is being replaced by AI. In a world where 2 seniors and AI can do the work of 10, there is no guarantee that "a place to gain experience" will be naturally provided to the young.

But waiting around won't change anything.

A field of practice is not something given to you. It is something you seek out and create for yourself.

This is an era where vibe coding is available. If you have an idea, you can build a prototype yourself. Even without being employed by a company, you can shape a product with your own hands. Publish it, get feedback, improve it. That cycle itself is practice.

If there's a new project at your company, raise your hand. The work you think "is too early for me" is exactly where growth happens. You might fail. But you learn far more from failure than from watching someone else succeed.

Join communities. Contribute to open-source projects. Present at study groups. Articulate your learning and share it publicly. You're a generation accustomed to self-expression through various channels, aren't you? The act of sharing itself becomes practice that sharpens your thinking.

And — this is the most important thing — tell the older generation, "Teach me."

Don't hesitate. Don't wait for the senior generation to offer voluntarily. Unfortunately, some among us seniors haven't realized the necessity of teaching. If you don't raise your voice, nothing starts.

"Let me work on this with you."
"Can you tell me why you made that decision?"
"How can I learn to think the way you do?"

Speaking these words is not embarrassing. It is not weakness. It is a declaration of will.

The theory was handed to you in Part I. Now comes practice. But the field of practice won't fall from the sky. Seek it with your own will.

---

In Part III, I speak to the side that should "answer" when you raise your voice — the senior generation.

---

# Part III: Let's Answer

## — A Warning to the Senior Generation

---

From here, the reader changes.

Parts I and II were written for the young. From here, I write for the senior generation — those on the same side as me — late 30s to 50s, holding established positions in organizations, benefiting from AI.

And I speak as one of them. This is a message directed at myself as well.

---

### 3-1. What Are We Doing?

Let me ask frankly.

What are we using AI for?

We're streamlining our work. We've cut report-writing time in half. We've delegated code reviews to AI. We auto-generate email drafts. We have AI summarize meeting notes. Productivity has certainly increased.

That in itself is not a bad thing. AI is a powerful tool. We should master it.

But while reaping these benefits, have we forgotten to ask ourselves one question?

**"What are we leaving for the next generation?"**

Work that once required 10 juniors can now be handled by 2 seniors and AI. Efficiency is up. Costs are down. From a management perspective, it may be the right decision. Results are delivered, evaluations are positive. And rewards follow.

But what has disappeared within that structure?

The opportunity for 8 juniors to gain experience.

Once, juniors learned by working alongside their seniors. Starting with simple tasks, gradually being entrusted with harder work, failing, receiving feedback, growing. Through that process alone — not from theory — practical wisdom was passed from generation to generation.

AI has broken that structure. AI has replaced the work juniors used to do, and the very space for juniors to gain experience is vanishing. And we seniors, while participating in this structural change, justify ourselves with the word "efficiency."

This is the disparity — between those who have and those who have not. An economic disparity that, in the not-too-distant future, will produce an intergenerational rupture.

---

### 3-2. We Too Were Raised This Way

Take a moment to remember your own past.

When you first entered the workforce. You knew nothing. You could barely use Excel or PowerPoint. Proposals you wrote for clients came back covered in red corrections. You made irrelevant comments in meetings and embarrassed yourself.

Someone taught you then.

A boss, a senior colleague, sometimes a veteran from another department — they gave you their time. "You should do it this way." "This is how you read these numbers." "What the client really wants is this." They interrupted their own work to pass their experience to us.

We stand on the foundation of that generosity.

Without those seniors, we wouldn't be in our current positions. We wouldn't have our current judgment. We wouldn't possess our current "experience." Our capabilities are built on the foundation of wisdom received from those who came before us.

And now, the ones about to break that chain — that's us.

It may not be intentional. There may be no malice. We may just be busy. It may simply be that, since AI handles things faster, there's no longer a need to teach juniors.

But the result is that the next generation is losing both "the space to gain experience" and "the seniors who pass on that experience."

---

### 3-3. What AI Cannot Pass On

Let me make one thing clear here.

I can already hear the counterargument: "Just let AI teach them." AI can be an excellent teacher. It organizes knowledge systematically, adjusts explanations to the individual's level, and answers questions 24 hours a day.

That's true. In transmitting knowledge, AI may surpass humans.

But there is something AI absolutely cannot pass on.

**Tacit knowledge gained through practice.**

The judgment to change the direction of a proposal the moment a client's expression darkens. The skill of deliberately creating an atmosphere that tolerates failure when team morale is low. The sense that something is "off" even when the numbers look right. Wisdom that can't be explained through logic, but that those who've experienced it understand — that kind of wisdom exists.

This tacit knowledge does not exist in AI's training data. AI has not yet learned to perceive real-world phenomena. And even when it can perceive the physical world, tacit knowledge is not articulated — so AI "cannot learn" it. Wisdom that hasn't been put into words can only be passed directly, from person to person, in the field of practice.

And those who bear the responsibility to design that field of practice and provide it to the young — that's us.

---

### 3-4. Let's Fulfill Our Responsibility

What specifically should we do?

**Intentionally design spaces for gaining experience, and provide them.**

Precisely because AI is replacing junior-level work, we need to deliberately carve out work where juniors can gain experience. If we pursue only efficiency, it's faster to leave everything to AI. But that is efficiency achieved at the cost of developing the next generation.

From the work that could be delegated to AI, intentionally assign portions to juniors. Have them work alongside AI. Show them how AI responds, and discuss together what's accurate and what's questionable in those responses. Transform the very process of mastering AI into an educational opportunity.

**Articulate your judgment process and pass it on.**

The reason we seniors use AI effectively is that we possess judgment frameworks accumulated unconsciously over the years. But those frameworks are, in most cases, not articulated. "I just felt this one was right." "In my experience, cases like this tend to go this way."

Consciously articulate that "just felt" and pass it to the next generation. Why did you make that decision? What past experiences shaped that intuition? It doesn't need to be perfectly articulated. The very act of trying to articulate it becomes a learning opportunity for the young.

**Recognize "teaching" as part of your work.**

Developing the next generation is not a leisure activity to do between tasks. It is the work itself. If our generation fails to pass wisdom to the next, in 5 years, in 10 years, there will be no one left to sustain the organization. That is an irreversible loss — for the organization and for society.

We too were raised by those who came before us. Repaying that debt to the next generation — that is our intergenerational responsibility. This is the history that has driven human progress, and it is a legacy worth preserving.

We must not break this chain.


---

# Epilogue: A Declaration of Intergenerational Co-Creation

---

Throughout this book, I have conveyed two things.

To the young — don't fear, let's arm ourselves. Rather than surrendering your heart to AI, hold your own axis, install a Thinking OS, sharpen yourself through the loop of theory and practice. And seek the field of practice with your own will.

To the senior generation — let's answer. The AI benefits we enjoy rest upon the foundation of experience received from those before us. Let's not break that chain, but pass it on to the next generation.

---

These two cannot stand alone.

No matter how loudly the young cry "teach me," if the seniors don't answer, that voice vanishes into the void. No matter how much the seniors want to teach, if the young lack the will to receive, the wisdom cannot be transmitted.

A bidirectional contract is needed.

The young "demand." Not waiting passively, but reaching out on their own. Voicing with intention what they want to learn and what experiences they want to gain.

The seniors "answer." In response to those voices, giving their time, articulating their experience, designing and providing fields of practice.

When this contract is fulfilled, the intergenerational gap of the AI era will begin to close.

---

I did not write this book to teach how to use AI.

This is a call to sustain — even in the age of AI — the most fundamental human endeavor: the passing of wisdom from one generation to the next, which humanity has protected throughout every era of technological evolution.

AI will continue to evolve. Today's common sense will be overturned tomorrow. Every technology eventually becomes obsolete. But the act of "passing wisdom learned from experience to the next generation" has not become obsolete once since the Stone Age.

Pass wisdom across generations. Those who receive it build new wisdom on top. Then pass it on again to the next generation.

This chain is what made us human.

No matter how intelligent AI becomes, this chain is something only humans can sustain.

So —

Young ones, let's demand.
And we will answer.
